# Machine Learning with Python - Week 3 Course

## Course Overview

In this course, we dive into the fundamentals of KNN, Decision Trees, and Regression Trees. These algorithms are widely used in machine learning for both classification and regression tasks. Understanding their principles and applications is crucial for building effective predictive models.

### K-Nearest Neighbors (KNN)

The course covers the K-Nearest Neighbors algorithm, which is a non-parametric algorithm used for classification and regression tasks. We learn how KNN works, including the calculation of distances between data points, determining the optimal number of neighbors, and handling categorical features. We also explore techniques for evaluating and tuning KNN models to achieve better performance.

### Decision Trees

The course introduces Decision Trees, which are powerful and interpretable models for both classification and regression tasks. We learn about the construction of decision trees using different algorithms such as ID3, C4.5, and CART. Additionally, we explore concepts like entropy, information gain, and Gini index to make decisions at each node of the tree. We also discuss strategies to handle missing values and handle categorical features in decision tree models.

### Regression Trees

The course delves into Regression Trees, which are a variation of decision trees specifically designed for regression tasks. We learn how regression trees are built, splitting criteria for regression problems, and techniques for pruning trees to prevent overfitting. We also explore ensemble methods like Random Forest, which utilize multiple decision trees to improve predictive accuracy.